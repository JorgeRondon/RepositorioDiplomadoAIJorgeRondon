{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ing. Jorge Eduardo Rons√≥n Ruiz\n",
    "#### jerondonr@unal.edu.co - 3012751445\n",
    "#### Universidad Nacional de Colombia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<center>ENTUBAMIENTO DE DATOS</center>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import logging\n",
    "import io\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "class TFRecord:\n",
    "    def __init__(self, labelmap_file) -> None:\n",
    "        f = open(labelmap_file, \"r\")\n",
    "        labelmap = f.read()\n",
    "        self.class_names = self.init_names(labelmap)\n",
    "\n",
    "    def init_names(self, labelmap) -> dict:\n",
    "        items = labelmap.split('item')[1:]\n",
    "        items_dict = {}\n",
    "        for item in items:\n",
    "            name = str(item.split('name')[1].split('\"')[1])\n",
    "            name_id = int(item.split('name')[1].split('id')[1].\\\n",
    "                                                split(\": \")[1].split('}')[0])\n",
    "\n",
    "            items_dict[name] = name_id\n",
    "        return items_dict\n",
    "\n",
    "    def class_text_to_int(self, row_label) -> int:\n",
    "        if self.class_names[row_label] is not None:\n",
    "            return self.class_names[row_label]\n",
    "        else:\n",
    "            None\n",
    "\n",
    "    def split(self, df, group):\n",
    "        data = namedtuple('data', ['filename', 'object'])\n",
    "        gb = df.groupby(group)\n",
    "        return [data(filename, gb.get_group(x)) for filename, x in \\\n",
    "                                            zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "    def create_tf(self, group, path):\n",
    "        with tf.io.gfile.GFile(os.path.join(path, '{}'\\\n",
    "                                        .format(group.filename)), 'rb') as fid:\n",
    "            encoded_jpg = fid.read()\n",
    "        encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "        image = Image.open(encoded_jpg_io)\n",
    "        width, height = image.size\n",
    "\n",
    "        filename = group.filename.encode('utf8')\n",
    "        image_format = b'jpg'\n",
    "        xmins = []\n",
    "        xmaxs = []\n",
    "        ymins = []\n",
    "        ymaxs = []\n",
    "        classes_text = []\n",
    "        classes = []\n",
    "\n",
    "        for index, row in group.object.iterrows():\n",
    "            xmins.append(row['xmin'] / width)\n",
    "            xmaxs.append(row['xmax'] / width)\n",
    "            ymins.append(row['ymin'] / height)\n",
    "            ymaxs.append(row['ymax'] / height)\n",
    "            classes_text.append(row['class'].encode('utf8'))\n",
    "            classes.append(self.class_text_to_int(row['class']))\n",
    "\n",
    "        tf_sample = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image/height': dataset_util.int64_feature(height),\n",
    "            'image/width': dataset_util.int64_feature(width),\n",
    "            'image/filename': dataset_util.bytes_feature(filename),\n",
    "            'image/source_id': dataset_util.bytes_feature(filename),\n",
    "            'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "            'image/format': dataset_util.bytes_feature(image_format),\n",
    "            'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "            'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "            'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "            'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "            'image/object/class/text':\\\n",
    "                                dataset_util.bytes_list_feature(classes_text),\n",
    "            'image/object/class/label':\\\n",
    "                                    dataset_util.int64_list_feature(classes),\n",
    "        }))\n",
    "        return tf_sample\n",
    "\n",
    "    def generate(self, output_path, image_dir, csv_input) -> None:\n",
    "        writer = tf.io.TFRecordWriter(output_path)\n",
    "        path = os.path.join(image_dir)\n",
    "        data = pd.read_csv(csv_input)\n",
    "        grouped = self.split(data, 'filename')\n",
    "\n",
    "        for group in grouped:\n",
    "            try:\n",
    "              tf_sample = self.create_tf(group, path)\n",
    "              writer.write(tf_sample.SerializeToString())\n",
    "            except:\n",
    "              continue\n",
    "        logging.info('Successfully created the TFRecords: {}'.format(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Generate tf record\")\n",
    "    parser.add_argument('-l', '--labelmap',\n",
    "                        help = 'Labelmap path',\n",
    "                        default = 'labelmap.txt',\n",
    "                        dest = 'labelmap_file'\n",
    "                        )\n",
    "    parser.add_argument('-o', '--output',\n",
    "                    help = 'Output path',\n",
    "                    default = 'train.record',\n",
    "                    dest = 'output_path'\n",
    "                    )\n",
    "\n",
    "    parser.add_argument('-i', '--imagesdir',\n",
    "                    help = 'Images directory',\n",
    "                    default = 'dataset/images',\n",
    "                    dest = 'image_dir'\n",
    "                    )\n",
    "\n",
    "    parser.add_argument('-csv', '--csvinput',\n",
    "                    help = 'CSV with images names',\n",
    "                    default = 'dataset/labels.csv',\n",
    "                    dest = 'csv_input'\n",
    "                    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    tf_record = TFRecord(args.labelmap_file)\n",
    "    tf_record.generate(args.output_path, args.image_dir, args.csv_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
